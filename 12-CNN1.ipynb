{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c70f5233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from random import shuffle\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5402893",
   "metadata": {},
   "source": [
    "## Convolution 결과 이미지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840fdbb",
   "metadata": {},
   "source": [
    "### 샘플 이미지 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76e4c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5021091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c0de134ec8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22968387",
   "metadata": {},
   "source": [
    "## 필터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "513e085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_filter = np.array([[1., 1., 1.], [0., 0., 0.], [-1., -1., -1.]])\n",
    "vertical_filter = np.array([[1., 0., -1.], [1., 0., -1.], [1., 0., -1.]])\n",
    "sharpen_filter = np.array([[0., -1., 0.], [-1., 5., -1.], [0., -1., 0.]])\n",
    "blur_filter = np.array([[0.11, 0.11, 0.11], [0.11, 0.11, 0.11], [0.11, 0.11, 0.11]])\n",
    "edge_1_filter = np.array([[1., 0., -1.], [0., 0., 0.], [-1., 0., 1.]])\n",
    "edge_2_filter = np.array([[0., -1., 0.], [-1., 4., -1.], [0., -1., 0.]])\n",
    "edge_3_filter = np.array([[-1., -1., -1.], [-1., 8., -1.], [-1., -1., -1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8906ba1",
   "metadata": {},
   "source": [
    "## Concolution 공식을 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dc5f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_simple(input_image, filter, filter_size):\n",
    "    original_image_size = input_image.shape[0]\n",
    "    conv_output_size = int(((original_image_size - filter_size)/1 + 1))\n",
    "    print(conv_output_size)\n",
    "    \n",
    "    filter_image = np.zeros((conv_output_size, conv_output_size))\n",
    "    \n",
    "    for i in range(conv_output_size):\n",
    "        for j in range(conv_output_size):\n",
    "            conv_result = input_image[i:(i+filter_size), j:(j+filter_size)] * filter\n",
    "            conv_sum = np.sum(conv_result)\n",
    "            \n",
    "            if(conv_sum > 255):\n",
    "                conv_sum = 255\n",
    "            \n",
    "            filter_image[i, j] = conv_sum\n",
    "            \n",
    "    return filter_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a441e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "vertical_filter_image = conv2d_simple(X_train[2], vertical_filter,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95418bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 26)\n"
     ]
    }
   ],
   "source": [
    "print(vertical_filter_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "142bfe05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c0db9e7b88>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_train[2], cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(vertical_filter_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2abe58be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'horizontal_filter_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp\\ipykernel_14520\\3444348324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhorizontal_filter_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'horizontal_filter_image' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(horizontal_filter_image, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sharpen_filter_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2546fe22",
   "metadata": {},
   "source": [
    "## Max Pooling 을 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpooling2d_simple(input_image):\n",
    "    image_x = input_image.shape[0]\n",
    "    image_y = input_image.shape[1]\n",
    "    \n",
    "    new_image_x = int(image_x / 2)\n",
    "    new_image_y = int(image_y / 2)\n",
    "    \n",
    "    max_pool_image = np.zeros((new_image_x, new_image_y))\n",
    "    \n",
    "    for i in range(0, image_x, 2):\n",
    "        for y in range(0, image_y, 2):\n",
    "            max_pool_image[int(x/2), int(y/2)]=np.max \n",
    "                np.max(input_image[x:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_filter_image = conv2d_simple(X_train[2], vertical_filter, 3)\n",
    "print(vertical_filter_image.shape)\n",
    "\n",
    "maxpooling2d_simple(vertical_filter_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b21a0f",
   "metadata": {},
   "source": [
    "## 2 . Simple CNN\n",
    "\n",
    "- mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0fdcf0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30e57d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4cdbf87",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'filters' and 'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp\\ipykernel_14520\\2145237870.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m model.add(Conv2D(filter=32, kernal_size=3, strides=(1,1),\n\u001b[0;32m      4\u001b[0m                 \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"VALID\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                 activation=\"relu\"))\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"VALID\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'filters' and 'kernel_size'"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filter=32, kernal_size=3, strides=(1,1),\n",
    "                input_shape=(28, 28, 1), padding=\"VALID\",\n",
    "                activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2), padding=\"VALID\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=Adam(learning_rate=0.001),\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afcebda",
   "metadata": {},
   "source": [
    "## Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f6ebe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527514b0",
   "metadata": {},
   "source": [
    "## 오답노트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "854497cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\wow\\anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                54090     \n",
      "=================================================================\n",
      "Total params: 54,410\n",
      "Trainable params: 54,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=(1,1),\n",
    "                input_shape=(28, 28, 1), padding=\"VALID\",\n",
    "                activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2), padding=\"VALID\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=Adam(learning_rate=0.01),\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d5e2476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 12s 244us/sample - loss: 0.1419 - acc: 0.9560 - val_loss: 0.0864 - val_acc: 0.9753\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 12s 242us/sample - loss: 0.0664 - acc: 0.9799 - val_loss: 0.0870 - val_acc: 0.9754\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 12s 242us/sample - loss: 0.0472 - acc: 0.9856 - val_loss: 0.0841 - val_acc: 0.9772\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 12s 240us/sample - loss: 0.0386 - acc: 0.9881 - val_loss: 0.0748 - val_acc: 0.9795\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 12s 243us/sample - loss: 0.0308 - acc: 0.9900 - val_loss: 0.1238 - val_acc: 0.9713\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 12s 242us/sample - loss: 0.0261 - acc: 0.9916 - val_loss: 0.0981 - val_acc: 0.9783\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 12s 240us/sample - loss: 0.0254 - acc: 0.9914 - val_loss: 0.1039 - val_acc: 0.9774\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 12s 241us/sample - loss: 0.0211 - acc: 0.9934 - val_loss: 0.1242 - val_acc: 0.9758\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 12s 242us/sample - loss: 0.0166 - acc: 0.9945 - val_loss: 0.1240 - val_acc: 0.9779\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 12s 243us/sample - loss: 0.0194 - acc: 0.9940 - val_loss: 0.1463 - val_acc: 0.9786\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10,\n",
    "         batch_size=50,\n",
    "         validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9b7c29e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_val = model.predict(X_test.reshape(-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a437d588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "[[6.0720929e-15 2.0466442e-23 1.7094553e-15 ... 1.0000000e+00\n",
      "  6.0107046e-13 1.5244748e-15]\n",
      " [2.9257384e-16 7.6128125e-19 1.0000000e+00 ... 5.3345946e-31\n",
      "  8.1743332e-20 9.1916277e-21]\n",
      " [5.7981775e-12 9.9999666e-01 1.2597032e-10 ... 1.6678437e-07\n",
      "  5.9964663e-08 1.6557665e-10]\n",
      " ...\n",
      " [3.9191606e-33 9.1117142e-29 1.5866262e-28 ... 5.9600669e-19\n",
      "  2.7108944e-18 3.0072871e-18]\n",
      " [2.9535387e-15 6.5322368e-33 9.3166759e-26 ... 3.8796548e-17\n",
      "  1.7936573e-12 4.7306500e-21]\n",
      " [4.2793287e-23 1.7404028e-35 2.5602195e-17 ... 2.8739868e-34\n",
      "  1.0110322e-21 9.8946823e-27]]\n"
     ]
    }
   ],
   "source": [
    "print(ret_val.shape)\n",
    "print(ret_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7e418dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index_label_pred_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp\\ipykernel_14520\\2922977246.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfalse_data_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_label_pred_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'index_label_pred_list' is not defined"
     ]
    }
   ],
   "source": [
    "false_data_index = np.random(len(index_label_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78064c39",
   "metadata": {},
   "source": [
    "## Simple CNN\n",
    "\n",
    "- C-> P -> C-> P ->F ->D ->D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f4493067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "abccef54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "=================================================================\n",
      "Total params: 9,568\n",
      "Trainable params: 9,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "## 1st Convolution Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding=\"SAME\",\n",
    "                input_shape=(28,28,1), activation=\"relu\"))\n",
    "model.add(MaxPool2D(padding=\"SAME\"))\n",
    "\n",
    "## 2nd Convolution Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding=\"SAME\",\n",
    "                input_shape=(28,28,1), activation=\"relu\"))\n",
    "model.add(MaxPool2D(padding=\"SAME\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36fed3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                50208     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 61,162\n",
      "Trainable params: 61,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6dc09a5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_2_input to have 4 dimensions, but got array with shape (60000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp\\ipykernel_14520\\3854150283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.fit(X_train, y_train, epochs=20, validation_split=0.2,\n\u001b[1;32m----> 6\u001b[1;33m          batch_size=1000)\n\u001b[0m",
      "\u001b[1;32mD:\\wow\\anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\wow\\anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\wow\\anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2471\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2473\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\wow\\anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    561\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_2_input to have 4 dimensions, but got array with shape (60000, 28, 28)"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer = Adam(learning_rate=0.01),\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, validation_split=0.2,\n",
    "         batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "29e68ad7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_2_input to have 4 dimensions, but got array with shape (10000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp\\ipykernel_14520\\3899891647.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\wow\\anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    830\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m   def predict(self,\n",
      "\u001b[1;32mD:\\wow\\anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    696\u001b[0m     return test_loop(\n\u001b[0;32m    697\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\wow\\anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2471\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2473\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\wow\\anaconda\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    561\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_2_input to have 4 dimensions, but got array with shape (10000, 28, 28)"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70ea34",
   "metadata": {},
   "source": [
    "## Deep CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e2da7",
   "metadata": {},
   "source": [
    "# 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "884ee662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. fashion mnist 사용\\n2. cpcpcpfd\\n3. 최소 90프로 이상의 성능\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. fashion mnist 사용\n",
    "2. c p c p c p f d\n",
    "3. 최소 90프로 이상의 성능\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "026dec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. fashion mnist 사용\\n2. c c p c c p f d\\n3. 최소 90프로 이상의 성능\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. fashion mnist 사용\n",
    "2. c c p c c p f d\n",
    "3. 최소 90프로 이상의 성능\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b6803be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "deb4233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 185s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2e5d6a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "098f1cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5f237d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "154c88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "55b13e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.imshow(X_train[i], cmap=\"gray\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d7c80c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (2816954255.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Temp\\ipykernel_14520\\2816954255.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    model.save(\".h5\")\u001b[0m\n\u001b[1;37m                     \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. cpcpcp, ccpccpcpcp 등 다양한 아키텍처로 구현해서 과적합을 최소로 하는 80프로 이상의 정확도를 가진\n",
    "모델을 만든 후 저장\n",
    "\n",
    "model.save(\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f6a69b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 86,346\n",
      "Trainable params: 86,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "## 1st Convolution Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding=\"SAME\",\n",
    "                input_shape=(32, 32, 3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(padding=\"SAME\"))\n",
    "\n",
    "## 2nd Convolution Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding=\"SAME\",\n",
    "                activation=\"relu\"))\n",
    "model.add(MaxPool2D(padding=\"SAME\"))\n",
    "\n",
    "## 3rd Convolution Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding=\"SAME\",\n",
    "                activation=\"relu\"))\n",
    "model.add(MaxPool2D(padding=\"SAME\"))\n",
    "\n",
    "## Flatten the output from 3D to 1D\n",
    "model.add(Flatten())\n",
    "\n",
    "## Fully connected layer\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "## Output layer\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7f8dacc0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=Adam(learning_rate=0.01),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "064940f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 22s 542us/sample - loss: 2.3032 - acc: 0.1002 - val_loss: 2.3029 - val_acc: 0.1025\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 23s 576us/sample - loss: 2.3029 - acc: 0.0984 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 23s 568us/sample - loss: 2.3028 - acc: 0.0993 - val_loss: 2.3029 - val_acc: 0.0977\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 23s 568us/sample - loss: 2.3029 - acc: 0.0994 - val_loss: 2.3030 - val_acc: 0.0980\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 23s 573us/sample - loss: 2.3031 - acc: 0.0979 - val_loss: 2.3028 - val_acc: 0.1014\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 23s 586us/sample - loss: 2.3029 - acc: 0.0977 - val_loss: 2.3028 - val_acc: 0.0997\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 24s 592us/sample - loss: 2.3029 - acc: 0.0992 - val_loss: 2.3026 - val_acc: 0.1022\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 24s 588us/sample - loss: 2.3030 - acc: 0.0987 - val_loss: 2.3028 - val_acc: 0.0977\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 24s 589us/sample - loss: 2.3029 - acc: 0.0987 - val_loss: 2.3028 - val_acc: 0.0977\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 24s 595us/sample - loss: 2.3029 - acc: 0.0994 - val_loss: 2.3028 - val_acc: 0.1014\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 24s 594us/sample - loss: 2.3028 - acc: 0.1013 - val_loss: 2.3029 - val_acc: 0.0980\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 24s 598us/sample - loss: 2.3028 - acc: 0.1007 - val_loss: 2.3028 - val_acc: 0.0980\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 24s 603us/sample - loss: 2.3028 - acc: 0.1000 - val_loss: 2.3027 - val_acc: 0.0952\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 24s 599us/sample - loss: 2.3028 - acc: 0.0991 - val_loss: 2.3029 - val_acc: 0.0952\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 25s 615us/sample - loss: 2.3029 - acc: 0.0981 - val_loss: 2.3030 - val_acc: 0.1014\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 24s 605us/sample - loss: 2.3028 - acc: 0.0995 - val_loss: 2.3027 - val_acc: 0.1014\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 24s 604us/sample - loss: 2.3029 - acc: 0.0969 - val_loss: 2.3027 - val_acc: 0.1003\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 24s 604us/sample - loss: 2.3028 - acc: 0.0990 - val_loss: 2.3028 - val_acc: 0.1003\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 24s 606us/sample - loss: 2.3029 - acc: 0.0984 - val_loss: 2.3028 - val_acc: 0.1022\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 24s 610us/sample - loss: 2.3029 - acc: 0.0994 - val_loss: 2.3030 - val_acc: 0.0977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c08081f9c8>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, validation_split=0.2, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a72ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
